{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drfperez/openair/blob/main/2026/Gencat2Openair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ==================================================\n",
        "# 1. C√ÄRREGA ROBUSTA DEL CSV\n",
        "# ==================================================\n",
        "print(\"Carrega el teu fitxer CSV:\")\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "df = pd.read_csv(\n",
        "    file_name,\n",
        "    sep=None,\n",
        "    engine='python',\n",
        "    decimal=',',\n",
        "    encoding='utf-8-sig'\n",
        ")\n",
        "\n",
        "if df.shape[1] == 1:\n",
        "    raise ValueError(\"‚ùå El CSV s'ha carregat com una sola columna.\")\n",
        "\n",
        "print(f\"‚úî CSV carregat: {df.shape[0]} files, {df.shape[1]} columnes\")\n",
        "\n",
        "# ==================================================\n",
        "# 2. NORMALITZAR I FER √öNIQUES LES COLUMNES\n",
        "# ==================================================\n",
        "df.columns = df.columns.str.strip()\n",
        "seen = {}\n",
        "new_cols = []\n",
        "for col in df.columns:\n",
        "    if col in seen:\n",
        "        seen[col] += 1\n",
        "        new_cols.append(f\"{col}_{seen[col]}\")\n",
        "    else:\n",
        "        seen[col] = 0\n",
        "        new_cols.append(col)\n",
        "df.columns = new_cols\n",
        "\n",
        "# ==================================================\n",
        "# 3. DETECCI√ì COLUMNES CLAU\n",
        "# ==================================================\n",
        "data_col = None\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == object and df[col].str.contains(r\"\\d{4}-\\d{2}-\\d{2}\", na=False).any():\n",
        "        data_col = col\n",
        "        break\n",
        "if data_col is None:\n",
        "    raise ValueError(\"‚ùå No s'ha pogut detectar la columna de data.\")\n",
        "\n",
        "contaminant_col = None\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == object and df[col].str.match(r\"^[A-Z]{1,5}$\", na=False).any():\n",
        "        contaminant_col = col\n",
        "        break\n",
        "if contaminant_col is None:\n",
        "    raise ValueError(\"‚ùå No s'ha pogut detectar la columna de contaminant.\")\n",
        "\n",
        "print(f\"‚úî Columna data detectada: {data_col}\")\n",
        "print(f\"‚úî Columna contaminant detectada: {contaminant_col}\")\n",
        "\n",
        "df = df.rename(columns={data_col: 'data', contaminant_col: 'pollutant'})\n",
        "\n",
        "# ==================================================\n",
        "# 4. CONVERSI√ì A DATETIME\n",
        "# ==================================================\n",
        "df['data'] = pd.to_datetime(df['data'], errors='coerce')\n",
        "df['data'] = df['data'].fillna(pd.Timestamp('1900-01-01'))\n",
        "\n",
        "# ==================================================\n",
        "# 5. VALIDACI√ì HORES\n",
        "# ==================================================\n",
        "hores = [f\"h{i:02}\" for i in range(1, 25)]\n",
        "for h in hores:\n",
        "    if h not in df.columns:\n",
        "        df[h] = 'NA'\n",
        "df[hores] = df[hores].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# ==================================================\n",
        "# 6. EXPANDIR HORES\n",
        "# ==================================================\n",
        "df_long = df.melt(\n",
        "    id_vars=['data', 'pollutant'],\n",
        "    value_vars=hores,\n",
        "    var_name='hora',\n",
        "    value_name='value'\n",
        ")\n",
        "\n",
        "df_long['hora'] = df_long['hora'].str.extract(r'(\\d+)').astype(int) - 1\n",
        "df_long['data'] = df_long['data'] + pd.to_timedelta(df_long['hora'], unit='h')\n",
        "df_long = df_long.drop(columns='hora')\n",
        "\n",
        "df_long['value'] = df_long['value'].fillna('NA')\n",
        "\n",
        "# ==================================================\n",
        "# 7. PIVOT WIDE (date, ordre decreixent)\n",
        "# ==================================================\n",
        "pivot_wide = df_long.pivot_table(\n",
        "    index='data',\n",
        "    columns='pollutant',\n",
        "    values='value',\n",
        "    aggfunc=lambda x: x.mean() if pd.api.types.is_numeric_dtype(x) else x.iloc[0],\n",
        "    fill_value='NA'\n",
        ").reset_index()\n",
        "\n",
        "pivot_wide = pivot_wide.sort_values('data', ascending=False)\n",
        "pivot_wide.columns = ['date' if col == 'data' else col.lower() for col in pivot_wide.columns]\n",
        "\n",
        "# ==================================================\n",
        "# 8. PIVOT LONG (date, ordre decreixent)\n",
        "# ==================================================\n",
        "pivot_long = df_long.copy()\n",
        "pivot_long['pollutant'] = pivot_long['pollutant'].str.lower()\n",
        "pivot_long = pivot_long[['data', 'pollutant', 'value']]\n",
        "pivot_long = pivot_long.rename(columns={'data': 'date'})\n",
        "pivot_long = pivot_long.sort_values('date', ascending=False)\n",
        "\n",
        "# ==================================================\n",
        "# 9. GUARDAR RESULTATS\n",
        "# ==================================================\n",
        "wide_file = 'processed_data_wide.csv'\n",
        "long_file = 'processed_data_long.csv'\n",
        "\n",
        "pivot_wide.to_csv(wide_file, index=False)\n",
        "pivot_long.to_csv(long_file, index=False)\n",
        "\n",
        "files.download(wide_file)\n",
        "files.download(long_file)\n",
        "\n",
        "print(\"‚úÖ PROC√âS COMPLETAT CORRECTAMENT\")\n",
        "print(f\"üìÅ Fitxer wide: {wide_file}, {pivot_wide.shape[0]} files, {pivot_wide.shape[1]} columnes\")\n",
        "print(f\"üìÅ Fitxer long: {long_file}, {pivot_long.shape[0]} files, {pivot_long.shape[1]} columnes\")"
      ],
      "metadata": {
        "id": "QfnuFTnenpLL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}