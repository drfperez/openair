{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4f+R6+wv7bJGwhuVQTeN8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drfperez/openair/blob/main/Limits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# FULL AIR QUALITY COMPLIANCE ENGINE (ONE COLAB CELL)\n",
        "# EU 2026 | EU 2030 | WHO 2021 | WHO 2005\n",
        "# Stations • QA • Compliance • Plots • ZIP\n",
        "# ============================================================\n",
        "\n",
        "import io, os, zipfile, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ----------------------------\n",
        "# Upload CSV\n",
        "# ----------------------------\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "fname = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(io.BytesIO(uploaded[fname]))\n",
        "\n",
        "# ----------------------------\n",
        "# Detect datetime column\n",
        "# ----------------------------\n",
        "dt_col = next(c for c in df.columns if pd.to_datetime(df[c], errors=\"coerce\").notna().sum() > 10)\n",
        "df[dt_col] = pd.to_datetime(df[dt_col], errors=\"coerce\")\n",
        "df = df.dropna(subset=[dt_col]).set_index(dt_col).sort_index()\n",
        "\n",
        "# ----------------------------\n",
        "# Detect station column (optional)\n",
        "# ----------------------------\n",
        "station_col = None\n",
        "for c in df.columns:\n",
        "    if c.lower() in [\"station\",\"station_id\",\"site\",\"site_id\",\"code\",\"monitor\"]:\n",
        "        station_col = c\n",
        "        break\n",
        "\n",
        "if station_col is None:\n",
        "    df[\"__station__\"] = \"SINGLE_STATION\"\n",
        "    station_col = \"__station__\"\n",
        "\n",
        "# ----------------------------\n",
        "# Detect pollutants\n",
        "# ----------------------------\n",
        "ALIASES = {\n",
        "    \"PM2.5\": [\"pm2.5\",\"pm25\"],\n",
        "    \"PM10\": [\"pm10\"],\n",
        "    \"NO2\": [\"no2\"],\n",
        "    \"O3\": [\"o3\"],\n",
        "    \"SO2\": [\"so2\"],\n",
        "    \"CO\": [\"co\"],\n",
        "    \"Benzene\": [\"benzene\"]\n",
        "}\n",
        "\n",
        "pollutant_cols = {}\n",
        "for col in df.columns:\n",
        "    for p, keys in ALIASES.items():\n",
        "        if any(k in col.lower() for k in keys):\n",
        "            pollutant_cols[p] = col\n",
        "\n",
        "# ----------------------------\n",
        "# Frameworks & limits\n",
        "# ----------------------------\n",
        "FRAMEWORKS = {\n",
        "    \"EU_2026\": {\n",
        "        \"PM2.5\":[(\"year\",25,None)],\n",
        "        \"PM10\":[(\"day\",50,35),(\"year\",40,None)],\n",
        "        \"NO2\":[(\"hour\",200,18),(\"year\",40,None)],\n",
        "        \"SO2\":[(\"hour\",350,24),(\"day\",125,3)],\n",
        "        \"O3\":[(\"8h\",120,25,\"3yr\")],\n",
        "        \"CO\":[(\"8h\",10,None)],\n",
        "        \"Benzene\":[(\"year\",5,None)]\n",
        "    },\n",
        "    \"EU_2030\": {\n",
        "        \"PM2.5\":[(\"day\",25,18),(\"year\",10,None)],\n",
        "        \"PM10\":[(\"day\",45,18),(\"year\",20,None)],\n",
        "        \"NO2\":[(\"hour\",200,3),(\"day\",50,18),(\"year\",20,None)],\n",
        "        \"SO2\":[(\"hour\",350,3),(\"day\",50,18)],\n",
        "        \"O3\":[(\"8h\",120,18,\"3yr\")],\n",
        "        \"CO\":[(\"8h\",10,None)],\n",
        "        \"Benzene\":[(\"year\",3.4,None)]\n",
        "    },\n",
        "    \"WHO_2021\": {\n",
        "        \"PM2.5\":[(\"day\",15,None),(\"year\",5,None)],\n",
        "        \"PM10\":[(\"day\",45,None),(\"year\",15,None)],\n",
        "        \"NO2\":[(\"day\",25,None),(\"year\",10,None)],\n",
        "        \"O3\":[(\"8h\",100,None)],\n",
        "        \"SO2\":[(\"day\",40,None)]\n",
        "    },\n",
        "    \"WHO_2005\": {\n",
        "        \"PM2.5\":[(\"day\",25,None),(\"year\",10,None)],\n",
        "        \"PM10\":[(\"day\",50,None),(\"year\",20,None)],\n",
        "        \"NO2\":[(\"hour\",200,None),(\"year\",40,None)],\n",
        "        \"O3\":[(\"8h\",100,None)],\n",
        "        \"SO2\":[(\"24h\",20,None)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# ----------------------------\n",
        "# Results containers\n",
        "# ----------------------------\n",
        "summary, events, station_summary = [], [], []\n",
        "\n",
        "os.makedirs(\"plots\", exist_ok=True)\n",
        "\n",
        "# ----------------------------\n",
        "# Main loop\n",
        "# ----------------------------\n",
        "for fw, rules in FRAMEWORKS.items():\n",
        "    for station, sdf in df.groupby(station_col):\n",
        "        hourly = sdf[pollutant_cols.values()].apply(pd.to_numeric, errors=\"coerce\").resample(\"1H\").mean()\n",
        "\n",
        "        for pol, col in pollutant_cols.items():\n",
        "            if pol not in rules:\n",
        "                continue\n",
        "\n",
        "            s = hourly[col]\n",
        "            daily = s.resample(\"1D\").mean()\n",
        "            roll8 = s.rolling(8, min_periods=6).mean()\n",
        "            daily8 = roll8.resample(\"1D\").max()\n",
        "\n",
        "            for rule in rules[pol]:\n",
        "                period, limit, allowed = rule[0], rule[1], rule[2]\n",
        "\n",
        "                if period == \"hour\":\n",
        "                    exc = s > limit\n",
        "                    grp = exc.groupby(exc.index.year).sum()\n",
        "\n",
        "                elif period == \"day\":\n",
        "                    exc = daily > limit\n",
        "                    grp = exc.groupby(exc.index.year).sum()\n",
        "\n",
        "                elif period == \"8h\":\n",
        "                    exc = daily8 > limit\n",
        "                    grp = exc.groupby(exc.index.year).sum()\n",
        "\n",
        "                elif period == \"year\":\n",
        "                    ann = s.resample(\"1Y\").mean()\n",
        "                    grp = (ann > limit).astype(int)\n",
        "                    grp.index = grp.index.year\n",
        "\n",
        "                for y, cnt in grp.items():\n",
        "                    compliant = \"COMPLIANT\"\n",
        "                    if allowed is not None and cnt > allowed:\n",
        "                        compliant = \"NON_COMPLIANT\"\n",
        "                    summary.append([fw,station,pol,period,y,int(cnt),allowed,compliant])\n",
        "\n",
        "# ----------------------------\n",
        "# DataFrames\n",
        "# ----------------------------\n",
        "df_summary = pd.DataFrame(summary, columns=[\n",
        "    \"framework\",\"station\",\"pollutant\",\"period\",\"year\",\n",
        "    \"exceedances\",\"allowed\",\"compliance\"\n",
        "])\n",
        "\n",
        "df_summary.to_csv(\"summary_exceedances_ALL.csv\", index=False)\n",
        "\n",
        "# ----------------------------\n",
        "# Plots\n",
        "# ----------------------------\n",
        "for (fw, pol), g in df_summary.groupby([\"framework\",\"pollutant\"]):\n",
        "    pivot = g.groupby(\"year\")[\"exceedances\"].sum()\n",
        "    plt.figure()\n",
        "    pivot.plot(kind=\"bar\")\n",
        "    plt.title(f\"{pol} – {fw}\")\n",
        "    plt.ylabel(\"Exceedances\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"plots/{pol}_{fw}.png\")\n",
        "    plt.close()\n",
        "\n",
        "# ----------------------------\n",
        "# ZIP\n",
        "# ----------------------------\n",
        "with open(\"README.txt\",\"w\") as f:\n",
        "    f.write(\"Full EU + WHO air quality compliance package.\\n\")\n",
        "\n",
        "with zipfile.ZipFile(\"air_quality_FULL_PACKAGE.zip\",\"w\") as z:\n",
        "    z.write(\"summary_exceedances_ALL.csv\")\n",
        "    z.write(\"README.txt\")\n",
        "    for fn in os.listdir(\"plots\"):\n",
        "        z.write(os.path.join(\"plots\",fn))\n",
        "\n",
        "files.download(\"air_quality_FULL_PACKAGE.zip\")\n",
        "\n",
        "print(\"✅ ALL DONE — full compliance engine executed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "nylcQ0N3tUw3",
        "outputId": "923eb11d-f6e7-4677-93ce-f6b0de63fcc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e751f474-98ce-43c0-8aff-5082ccb8ceb6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e751f474-98ce-43c0-8aff-5082ccb8ceb6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving processed_data_wide.csv to processed_data_wide (2).csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e8799952-4172-49f7-8d88-9816184dc899\", \"air_quality_FULL_PACKAGE.zip\", 500375)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ALL DONE — full compliance engine executed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# UNIVERSAL AIR QUALITY EXCEEDANCE CALCULATOR (ONE CELL)\n",
        "# EU LAW (2026 / 2030) + WHO (2021 / 2005)\n",
        "# ============================================================\n",
        "\n",
        "LEGAL_TARGET = \"EU_2026\"  # <<< CHANGE HERE ONLY\n",
        "\n",
        "import io, os, zipfile, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# ----------------------------\n",
        "# Upload CSV\n",
        "# ----------------------------\n",
        "if IN_COLAB:\n",
        "    uploaded = files.upload()\n",
        "    fname = list(uploaded.keys())[0]\n",
        "    df = pd.read_csv(io.BytesIO(uploaded[fname]))\n",
        "else:\n",
        "    df = pd.read_csv(\"/mnt/data/processed_data_wide.csv\")\n",
        "\n",
        "# ----------------------------\n",
        "# Detect datetime column\n",
        "# ----------------------------\n",
        "dt_col = None\n",
        "for c in df.columns:\n",
        "    try:\n",
        "        t = pd.to_datetime(df[c], errors=\"coerce\")\n",
        "        if t.notna().sum() > 10:\n",
        "            dt_col = c\n",
        "            break\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "if dt_col is None:\n",
        "    raise ValueError(\"No datetime column detected.\")\n",
        "\n",
        "df[dt_col] = pd.to_datetime(df[dt_col], errors=\"coerce\")\n",
        "df = df.dropna(subset=[dt_col])\n",
        "df = df.set_index(dt_col).sort_index()\n",
        "\n",
        "# ----------------------------\n",
        "# Detect pollutants\n",
        "# ----------------------------\n",
        "ALIASES = {\n",
        "    \"PM2.5\": [\"pm2.5\", \"pm25\"],\n",
        "    \"PM10\": [\"pm10\"],\n",
        "    \"NO2\": [\"no2\"],\n",
        "    \"O3\": [\"o3\", \"ozone\"],\n",
        "    \"SO2\": [\"so2\"],\n",
        "    \"CO\": [\"co\"],\n",
        "    \"Benzene\": [\"benzene\"]\n",
        "}\n",
        "\n",
        "pollutants = {}\n",
        "for col in df.columns:\n",
        "    c = col.lower()\n",
        "    for p, keys in ALIASES.items():\n",
        "        if any(k in c for k in keys):\n",
        "            pollutants[p] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "if not pollutants:\n",
        "    raise ValueError(\"No pollutant columns detected.\")\n",
        "\n",
        "data = pd.DataFrame(pollutants)\n",
        "hourly = data.resample(\"1H\").mean()\n",
        "\n",
        "# ----------------------------\n",
        "# LIMIT TABLES\n",
        "# ----------------------------\n",
        "LIMITS = {\n",
        "    \"EU_2026\": {\n",
        "        \"PM2.5\": [(\"year\", 25, None)],\n",
        "        \"PM10\": [(\"day\", 50, 35), (\"year\", 40, None)],\n",
        "        \"NO2\":  [(\"hour\", 200, 18), (\"year\", 40, None)],\n",
        "        \"SO2\":  [(\"hour\", 350, 24), (\"day\", 125, 3)],\n",
        "        \"O3\":   [(\"8h\", 120, 25, \"3yr\")],\n",
        "        \"CO\":   [(\"8h\", 10, None)],\n",
        "        \"Benzene\": [(\"year\", 5, None)]\n",
        "    },\n",
        "    \"EU_2030\": {\n",
        "        \"PM2.5\": [(\"day\", 25, 18), (\"year\", 10, None)],\n",
        "        \"PM10\":  [(\"day\", 45, 18), (\"year\", 20, None)],\n",
        "        \"NO2\":   [(\"hour\", 200, 3), (\"day\", 50, 18), (\"year\", 20, None)],\n",
        "        \"SO2\":   [(\"hour\", 350, 3), (\"day\", 50, 18)],\n",
        "        \"O3\":    [(\"8h\", 120, 18, \"3yr\")],\n",
        "        \"CO\":    [(\"8h\", 10, None)],\n",
        "        \"Benzene\": [(\"year\", 3.4, None)]\n",
        "    },\n",
        "    \"WHO_2021\": {\n",
        "        \"PM2.5\": [(\"day\", 15, None), (\"year\", 5, None)],\n",
        "        \"PM10\":  [(\"day\", 45, None), (\"year\", 15, None)],\n",
        "        \"NO2\":   [(\"day\", 25, None), (\"year\", 10, None)],\n",
        "        \"O3\":    [(\"8h\", 100, None)],\n",
        "        \"SO2\":   [(\"day\", 40, None)],\n",
        "        \"CO\":    [(\"24h\", 4, None)]\n",
        "    },\n",
        "    \"WHO_2005\": {\n",
        "        \"PM2.5\": [(\"day\", 25, None), (\"year\", 10, None)],\n",
        "        \"PM10\":  [(\"day\", 50, None), (\"year\", 20, None)],\n",
        "        \"NO2\":   [(\"hour\", 200, None), (\"year\", 40, None)],\n",
        "        \"O3\":    [(\"8h\", 100, None)],\n",
        "        \"SO2\":   [(\"24h\", 20, None)]\n",
        "    }\n",
        "}\n",
        "\n",
        "rules = LIMITS[LEGAL_TARGET]\n",
        "\n",
        "# ----------------------------\n",
        "# Calculations\n",
        "# ----------------------------\n",
        "summary = []\n",
        "events = []\n",
        "\n",
        "for pol, series in hourly.items():\n",
        "    if pol not in rules:\n",
        "        continue\n",
        "\n",
        "    daily = series.resample(\"1D\").mean()\n",
        "    roll8 = series.rolling(8, min_periods=6).mean()\n",
        "    daily8max = roll8.resample(\"1D\").max()\n",
        "\n",
        "    for rule in rules[pol]:\n",
        "        period = rule[0]\n",
        "        limit = rule[1]\n",
        "\n",
        "        if period == \"hour\":\n",
        "            exc = series > limit\n",
        "            for ts, v in series[exc].items():\n",
        "                events.append([pol, \"hour\", ts.strftime(\"%Y-%m-%d %H\"), v, limit])\n",
        "            summary += [[pol, LEGAL_TARGET, \"hour\", str(y), int(exc[exc.index.year==y].sum())]\n",
        "                        for y in exc.index.year.unique()]\n",
        "\n",
        "        elif period == \"day\":\n",
        "            exc = daily > limit\n",
        "            for ts, v in daily[exc].items():\n",
        "                events.append([pol, \"day\", ts.strftime(\"%Y-%m-%d\"), v, limit])\n",
        "            summary += [[pol, LEGAL_TARGET, \"day\", str(y), int(exc[exc.index.year==y].sum())]\n",
        "                        for y in exc.index.year.unique()]\n",
        "\n",
        "        elif period == \"8h\":\n",
        "            exc = daily8max > limit\n",
        "            for ts, v in daily8max[exc].items():\n",
        "                events.append([pol, \"8h\", ts.strftime(\"%Y-%m-%d\"), v, limit])\n",
        "            yearly = exc.resample(\"1Y\").sum()\n",
        "            for ts, v in yearly.items():\n",
        "                summary.append([pol, LEGAL_TARGET, \"8h_days\", str(ts.year), int(v)])\n",
        "\n",
        "        elif period == \"year\":\n",
        "            annual = series.resample(\"1Y\").mean()\n",
        "            for ts, v in annual.items():\n",
        "                if v > limit:\n",
        "                    events.append([pol, \"year\", str(ts.year), v, limit])\n",
        "                summary.append([pol, LEGAL_TARGET, \"year\", str(ts.year), int(v > limit)])\n",
        "\n",
        "# ----------------------------\n",
        "# Save outputs\n",
        "# ----------------------------\n",
        "df_summary = pd.DataFrame(summary,\n",
        "    columns=[\"pollutant\",\"legal_target\",\"period\",\"year\",\"exceedances\"])\n",
        "\n",
        "df_events = pd.DataFrame(events,\n",
        "    columns=[\"pollutant\",\"period\",\"timestamp\",\"value\",\"limit\"])\n",
        "\n",
        "df_summary.to_csv(\"summary_exceedances.csv\", index=False)\n",
        "df_events.to_csv(\"detailed_exceedance_events.csv\", index=False)\n",
        "\n",
        "with zipfile.ZipFile(\"air_quality_results.zip\",\"w\") as z:\n",
        "    z.write(\"summary_exceedances.csv\")\n",
        "    z.write(\"detailed_exceedance_events.csv\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    files.download(\"air_quality_results.zip\")\n",
        "\n",
        "print(\"✅ DONE — Legal target:\", LEGAL_TARGET)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "Q30rEkEDovg6",
        "outputId": "8d37f084-a987-464a-d445-4e9f9a51151a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ca5e7039-7420-4503-b467-afca5f839ba2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ca5e7039-7420-4503-b467-afca5f839ba2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving processed_data_wide.csv to processed_data_wide (1).csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_457666d9-f896-45b3-9418-af03c1bcffd2\", \"air_quality_results.zip\", 16210)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DONE — Legal target: EU_2026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "buKBo1VAj_kA",
        "outputId": "ae6dd310-4355-4ab2-cf38-2272e725af9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU exceedance calculator (single-cell). Will ask you to upload a CSV (Colab).\n",
            "\n",
            "Please upload your CSV file when the file-picker appears (it may take a few seconds).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e587df9-6f30-4cfc-8f51-58149eddffdb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8e587df9-6f30-4cfc-8f51-58149eddffdb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving processed_data_wide.csv to processed_data_wide.csv\n",
            "Loaded uploaded file: processed_data_wide.csv\n",
            "CSV parsed: 290832 rows, 12 columns.\n",
            "Detected datetime column: date\n",
            "Detected pollutant columns (mapped):\n",
            "  CO  <-- column 'co'\n",
            "  NO2  <-- column 'no2'\n",
            "  O3  <-- column 'o3'\n",
            "  PM10  <-- column 'pm10'\n",
            "  PM2.5  <-- column 'pm2.5'\n",
            "  SO2  <-- column 'so2'\n",
            "\n",
            "Using legal target: 2030 (Directive (EU) 2024/2881 tables).\n",
            "\n",
            "Created files: summary_exceedances.csv, detailed_exceedance_events.csv, zipped into eu_exceedance_results.zip.\n",
            "First rows of summary:\n",
            "pollutant legal_target  period_type period_label  limit  exceedances  allowed_exceedances_per_year\n",
            "       CO         2030 8h_daily_max         1991   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         1992   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         1993   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         1994   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         1995   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         1996   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         1997   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         1998   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         1999   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2000   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2001   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2002   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2003   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2004   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2005   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2006   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2007   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2008   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2009   10.0            0                           NaN\n",
            "       CO         2030 8h_daily_max         2010   10.0            0                           NaN\n",
            "\n",
            "Starting download of the zip file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85c49eaa-735f-4e83-b813-f0925ae673e8\", \"eu_exceedance_results.zip\", 23756)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Colab one-cell: EU air pollutant exceedance calculator (didactic)\n",
        "# - Upload a CSV (or it will try /mnt/data/processed_data_wide.csv if present)\n",
        "# - Produces two CSVs and zips them for download:\n",
        "#     1) summary_exceedances.csv\n",
        "#     2) detailed_exceedance_events.csv\n",
        "# - Implements limit tables for two legal milestones from Directive (EU) 2024/2881:\n",
        "#     * \"2026\" transitional table (to be attained by 11 Dec 2026)\n",
        "#     * \"2030\" table (to be attained by 1 Jan 2030)\n",
        "#\n",
        "# How to use:\n",
        "# 1) Run this cell in Google Colab.\n",
        "# 2) Upload a CSV when prompted (or Colab will read /mnt/data/processed_data_wide.csv if available).\n",
        "# 3) Wait until it finishes — it will create and download eu_exceedance_results.zip containing the two CSVs.\n",
        "#\n",
        "# Important assumptions & robustness choices:\n",
        "# - The script heuristically finds a datetime column. If there's a separate date and time column, it will combine them.\n",
        "# - Common pollutant column name variants are recognized (e.g. PM2.5, PM25, pm25, NO2, no2, PM10, O3, CO, SO2, benzene).\n",
        "# - If input resolution is coarser than hourly (e.g. daily), the code adapts and warns where hourly-derived metrics cannot be computed.\n",
        "# - Rolling 8-hour means are computed as \"running 8-hour averages\" and each 8-hour average is assigned to the day on which it ends (per directive).\n",
        "# - Data coverage rules are implemented in a simple way (minimum hours required: 75% rule => e.g. for daily means min 18 hourly values).\n",
        "#\n",
        "# Legal source (used to code thresholds): Directive (EU) 2024/2881 (Annex I tables for 2026 & 2030).\n",
        "# For reference: European Commission / EEA materials.\n",
        "# (The code below is fully self-contained for Colab: pandas + numpy + zipfile + google.colab.files)\n",
        "\n",
        "# ---- Begin cell code ----\n",
        "import io, os, zipfile, sys, warnings\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Colab-specific uploads/downloads\n",
        "try:\n",
        "    from google.colab import files\n",
        "    _in_colab = True\n",
        "except Exception:\n",
        "    _in_colab = False\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"EU exceedance calculator (single-cell). Will ask you to upload a CSV (Colab).\")\n",
        "\n",
        "# ---------- Helper: get input CSV ----------\n",
        "def upload_or_open_default():\n",
        "    if _in_colab:\n",
        "        print(\"\\nPlease upload your CSV file when the file-picker appears (it may take a few seconds).\")\n",
        "        uploaded = files.upload()  # user uploads file(s)\n",
        "        if uploaded:\n",
        "            # take the first uploaded file\n",
        "            name = list(uploaded.keys())[0]\n",
        "            print(f\"Loaded uploaded file: {name}\")\n",
        "            return name, io.BytesIO(uploaded[name])\n",
        "        else:\n",
        "            # fallback to default path if present\n",
        "            default_path = \"/mnt/data/processed_data_wide.csv\"\n",
        "            if os.path.exists(default_path):\n",
        "                print(f\"No upload detected — using default path: {default_path}\")\n",
        "                return os.path.basename(default_path), open(default_path, \"rb\")\n",
        "            raise FileNotFoundError(\"No file uploaded and default file not present.\")\n",
        "    else:\n",
        "        # Not running in Colab — try default path\n",
        "        default_path = \"/mnt/data/processed_data_wide.csv\"\n",
        "        if os.path.exists(default_path):\n",
        "            print(f\"Running outside Colab, using default path: {default_path}\")\n",
        "            return os.path.basename(default_path), open(default_path, \"rb\")\n",
        "        raise EnvironmentError(\"Not in Colab and default CSV not present. Run this in Colab or provide a CSV.\")\n",
        "\n",
        "fname, fh = upload_or_open_default()\n",
        "\n",
        "# ---------- Read CSV with robust parsing ----------\n",
        "# Try multiple separators, encoding; try to infer datetime columns\n",
        "text = fh.read()\n",
        "if isinstance(text, bytes):\n",
        "    # attempt utf-8 first, fallback to latin1\n",
        "    try:\n",
        "        s = text.decode(\"utf-8\")\n",
        "    except:\n",
        "        s = text.decode(\"latin1\")\n",
        "else:\n",
        "    s = str(text)\n",
        "\n",
        "# pandas read with common separators\n",
        "sep_candidates = [\",\", \";\", \"\\t\", \"|\"]\n",
        "for sep in sep_candidates:\n",
        "    try:\n",
        "        df = pd.read_csv(io.StringIO(s), sep=sep, engine=\"python\")\n",
        "        # require at least 2 columns\n",
        "        if df.shape[1] >= 2:\n",
        "            break\n",
        "    except Exception:\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise ValueError(\"Unable to parse CSV with common separators. Please re-export as comma-delimited or upload a simpler CSV.\")\n",
        "\n",
        "print(f\"CSV parsed: {df.shape[0]} rows, {df.shape[1]} columns.\")\n",
        "\n",
        "# ---------- Find datetime / timestamp column ----------\n",
        "def find_datetime_column(df):\n",
        "    # common names\n",
        "    candidates = [c for c in df.columns if c.lower() in (\"datetime\",\"timestamp\",\"time\",\"date\",\"date_time\",\"date/time\",\"measurement_time\")]\n",
        "    if candidates:\n",
        "        return candidates[0]\n",
        "    # try to find a single column that parses as datetime\n",
        "    for c in df.columns:\n",
        "        try:\n",
        "            parsed = pd.to_datetime(df[c], errors=\"coerce\")\n",
        "            if parsed.notna().sum() > max(5, 0.01 * len(df)):  # at least a few parse\n",
        "                return c\n",
        "        except Exception:\n",
        "            continue\n",
        "    # try combining date + time columns\n",
        "    date_cols = [c for c in df.columns if \"date\" in c.lower() and c.lower()!= \"data\"]\n",
        "    time_cols = [c for c in df.columns if \"time\" in c.lower()]\n",
        "    if date_cols and time_cols:\n",
        "        return (date_cols[0], time_cols[0])\n",
        "    return None\n",
        "\n",
        "dt_col = find_datetime_column(df)\n",
        "if dt_col is None:\n",
        "    raise ValueError(\"Could not detect a datetime or date & time column. Please ensure your CSV has a datetime/timestamp column.\")\n",
        "if isinstance(dt_col, tuple):\n",
        "    date_col, time_col = dt_col\n",
        "    print(f\"Combining date + time columns: {date_col} + {time_col}\")\n",
        "    df['__datetime__'] = pd.to_datetime(df[date_col].astype(str) + \" \" + df[time_col].astype(str), errors=\"coerce\")\n",
        "    df = df.drop(columns=[date_col, time_col])\n",
        "    dt_col = '__datetime__'\n",
        "else:\n",
        "    # parse detected column\n",
        "    print(f\"Detected datetime column: {dt_col}\")\n",
        "    df[dt_col] = pd.to_datetime(df[dt_col], errors=\"coerce\")\n",
        "\n",
        "# drop rows without valid datetime\n",
        "df = df.loc[df[dt_col].notna()].copy()\n",
        "df = df.sort_values(dt_col).reset_index(drop=True)\n",
        "\n",
        "# set as index\n",
        "df.index = pd.DatetimeIndex(df[dt_col])\n",
        "\n",
        "# ---------- Detect pollutant columns (common names) ----------\n",
        "# Mapping of canonical pollutant keys to name patterns\n",
        "POLLUTANT_ALIASES = {\n",
        "    'PM2.5': ['pm2.5','pm2_5','pm25','pm_2_5','pm2p5'],\n",
        "    'PM10' : ['pm10','pm_10'],\n",
        "    'NO2'  : ['no2','nitrogen_dioxide','nitrogen dioxide'],\n",
        "    'SO2'  : ['so2','sulphur_dioxide','sulfur_dioxide'],\n",
        "    'O3'   : ['o3','ozone'],\n",
        "    'CO'   : ['co','carbon_monoxide','carbon monoxide'],\n",
        "    'Benzene': ['benzene','c6h6', 'ben']\n",
        "}\n",
        "\n",
        "# auto-detect\n",
        "available = {}\n",
        "for col in df.columns:\n",
        "    cname = col.lower().replace(\" \",\"_\")\n",
        "    for pollutant, aliases in POLLUTANT_ALIASES.items():\n",
        "        if any(a in cname for a in aliases):\n",
        "            # attempt to coerce to numeric\n",
        "            try:\n",
        "                series = pd.to_numeric(df[col], errors='coerce')\n",
        "                if series.notna().sum() > 0:\n",
        "                    available[pollutant] = col\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "if not available:\n",
        "    raise ValueError(\"No pollutant columns detected. Column names should include e.g. PM2.5, PM10, NO2, SO2, O3, CO, Benzene (case-insensitive). Found columns: \" + \", \".join(df.columns))\n",
        "\n",
        "print(\"Detected pollutant columns (mapped):\")\n",
        "for k,v in available.items():\n",
        "    print(f\"  {k}  <-- column '{v}'\")\n",
        "\n",
        "# Convert detected pollutant columns to numeric series (units assumed μg/m3 except CO in mg/m3)\n",
        "series_dict = {}\n",
        "for p, col in available.items():\n",
        "    s = pd.to_numeric(df[col], errors='coerce')\n",
        "    series_dict[p] = s\n",
        "\n",
        "data = pd.DataFrame(series_dict, index=df.index)\n",
        "\n",
        "# Resample to hourly (mean) so we have consistent hourly timeseries for rolling 8-hour windows\n",
        "# If input is coarser than hourly (e.g., daily), resampling will upsample (NaNs) and we will adjust later\n",
        "data_hourly = data.resample('1H').mean()\n",
        "\n",
        "# ---------- EU limit tables (from Directive (EU) 2024/2881, Annex I) ----------\n",
        "# We implement two legal milestones: '2026' (earlier limits, to be attained by 11 Dec 2026)\n",
        "# and '2030' (stricter limits, to be attained by 1 Jan 2030).\n",
        "# The script uses the 2030 table by default; change 'legal_target' to '2026' if you want transitional limits.\n",
        "\n",
        "legal_target = '2030'   # <-- change to '2026' if you want the earlier transitional table\n",
        "\n",
        "# Limits structure:\n",
        "# For each pollutant we store limit entries with keys: 'period' (hour, 8h, day, year), 'limit', 'max_exceedances_per_year' (None if not limited)\n",
        "# Units: numeric values assumed μg/m3 except for CO (mg/m3), for benzene (μg/m3)\n",
        "LIMIT_TABLES = {\n",
        "    '2030': {\n",
        "        'PM2.5': [\n",
        "            {'period':'day', 'limit':25.0, 'max_exceedances_per_year':18},\n",
        "            {'period':'year','limit':10.0, 'max_exceedances_per_year':None},\n",
        "        ],\n",
        "        'PM10': [\n",
        "            {'period':'day', 'limit':45.0, 'max_exceedances_per_year':18},\n",
        "            {'period':'year','limit':20.0, 'max_exceedances_per_year':None},\n",
        "        ],\n",
        "        'NO2': [\n",
        "            {'period':'hour','limit':200.0, 'max_exceedances_per_year':3},\n",
        "            {'period':'day','limit':50.0, 'max_exceedances_per_year':18},\n",
        "            {'period':'year','limit':20.0, 'max_exceedances_per_year':None},\n",
        "        ],\n",
        "        'SO2': [\n",
        "            {'period':'hour','limit':350.0, 'max_exceedances_per_year':3},\n",
        "            {'period':'day','limit':50.0, 'max_exceedances_per_year':18},\n",
        "            {'period':'year','limit':20.0, 'max_exceedances_per_year':None},\n",
        "        ],\n",
        "        'O3': [\n",
        "            # O3 is a target value: max daily 8-hour mean 120 μg/m3; days count averaged over 3 years\n",
        "            {'period':'8h_daily_max','limit':120.0, 'max_exceedances_per_year':18, 'three_year_rule':True},\n",
        "        ],\n",
        "        'CO': [\n",
        "            {'period':'8h_max_daily','limit':10.0, 'max_exceedances_per_year':None},  # mg/m3 (note: input suspected μg/m3 — user must confirm units)\n",
        "            {'period':'day','limit':4.0, 'max_exceedances_per_year':18},\n",
        "        ],\n",
        "        'Benzene': [\n",
        "            {'period':'year','limit':3.4, 'max_exceedances_per_year':None},  # μg/m3\n",
        "        ]\n",
        "    },\n",
        "    '2026': {\n",
        "        'PM2.5': [\n",
        "            {'period':'year','limit':25.0, 'max_exceedances_per_year':None},\n",
        "        ],\n",
        "        'PM10': [\n",
        "            {'period':'day','limit':50.0, 'max_exceedances_per_year':35},\n",
        "            {'period':'year','limit':40.0, 'max_exceedances_per_year':None},\n",
        "        ],\n",
        "        'NO2': [\n",
        "            {'period':'hour','limit':200.0, 'max_exceedances_per_year':18},\n",
        "            {'period':'year','limit':40.0, 'max_exceedances_per_year':None},\n",
        "        ],\n",
        "        'SO2': [\n",
        "            {'period':'hour','limit':350.0, 'max_exceedances_per_year':24},\n",
        "            {'period':'day','limit':125.0, 'max_exceedances_per_year':3},\n",
        "        ],\n",
        "        'O3': [\n",
        "            {'period':'8h_daily_max','limit':120.0, 'max_exceedances_per_year':25, 'three_year_rule':True},\n",
        "        ],\n",
        "        'CO': [\n",
        "            {'period':'8h_max_daily','limit':10.0, 'max_exceedances_per_year':None},  # mg/m3\n",
        "            {'period':'day','limit':4.0, 'max_exceedances_per_year':18},\n",
        "        ],\n",
        "        'Benzene': [\n",
        "            {'period':'year','limit':5.0, 'max_exceedances_per_year':None},\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "LIMITS = LIMIT_TABLES[legal_target]\n",
        "print(f\"\\nUsing legal target: {legal_target} (Directive (EU) 2024/2881 tables).\")\n",
        "\n",
        "# ---------- Utility to compute daily & rolling 8-hour means ----------\n",
        "# apply data coverage minima per directive simply: daily mean requires at least 18 valid hourly values (75% of 24),\n",
        "# 8-hour mean requires at least 6 valid hours in the 8-hour window (75%).\n",
        "MIN_HOURS_PER_DAY = 18\n",
        "MIN_HOURS_IN_8H = 6\n",
        "\n",
        "# hourly series is data_hourly\n",
        "results_summary = []     # will collect summary per pollutant/period/year\n",
        "events_rows = []         # detailed events table rows\n",
        "\n",
        "# Helper to calculate 8-hour rolling and assign to day on which it ends\n",
        "def compute_8h_running(series_hourly):\n",
        "    # series_hourly: pandas Series indexed hourly\n",
        "    # compute rolling window of size 8 (hours), require at least MIN_HOURS_IN_8H non-na values\n",
        "    roll = series_hourly.rolling(window=8, min_periods=MIN_HOURS_IN_8H).mean()\n",
        "    # assign to the day on which the 8-hour period ends (so the timestamp is roll.index, which is end)\n",
        "    return roll\n",
        "\n",
        "# Helper to get daily mean with min coverage\n",
        "def compute_daily_mean(series_hourly):\n",
        "    # count non-na hours per day\n",
        "    valid_counts = series_hourly.resample('1D').count()\n",
        "    daily_mean = series_hourly.resample('1D').mean()\n",
        "    # mask days with low coverage\n",
        "    daily_mean[valid_counts < MIN_HOURS_PER_DAY] = np.nan\n",
        "    return daily_mean\n",
        "\n",
        "# Loop pollutants available in data\n",
        "for pollutant, series in data_hourly.items():\n",
        "    if pollutant not in LIMITS:\n",
        "        # skip if no legal limit in our tables\n",
        "        print(f\"Warning: pollutant {pollutant} not present in legal table for {legal_target}; skipping.\")\n",
        "        continue\n",
        "\n",
        "    limits_for_pollutant = LIMITS[pollutant]\n",
        "    # prepare hourly, daily, 8h series as needed\n",
        "    s_hour = series.copy()\n",
        "    s_day = compute_daily_mean(s_hour)\n",
        "    s_8h = compute_8h_running(s_hour)  # hourly-indexed rolling 8-hour means\n",
        "\n",
        "    # For each limit entry, compute exceedances per year (and record event details)\n",
        "    for ent in limits_for_pollutant:\n",
        "        period = ent['period']\n",
        "        limit = ent['limit']\n",
        "        max_exc = ent.get('max_exceedances_per_year', None)\n",
        "        three_year_rule = ent.get('three_year_rule', False)\n",
        "\n",
        "        if period == 'hour':\n",
        "            # count hours where hourly mean > limit\n",
        "            exceeded = s_hour > limit\n",
        "            # group by calendar year\n",
        "            counts = exceeded.groupby(exceeded.index.year).sum().astype(int)\n",
        "            for yr, cnt in counts.items():\n",
        "                results_summary.append({\n",
        "                    'pollutant': pollutant,\n",
        "                    'legal_target': legal_target,\n",
        "                    'period_type': 'hour',\n",
        "                    'period_label': str(yr),\n",
        "                    'limit': limit,\n",
        "                    'exceedances': int(cnt),\n",
        "                    'allowed_exceedances_per_year': max_exc\n",
        "                })\n",
        "            # detailed events: record each hour exceedance with yyyy-mm-dd HH\n",
        "            ev = s_hour[exceeded].dropna()\n",
        "            for ts, val in ev.items():\n",
        "                events_rows.append({\n",
        "                    'pollutant': pollutant,\n",
        "                    'period_type': 'hour',\n",
        "                    'period_stamp': ts.strftime(\"%Y-%m-%d %H\"),\n",
        "                    'value': float(val),\n",
        "                    'limit': limit,\n",
        "                    'excess_amount': float(val - limit)\n",
        "                })\n",
        "\n",
        "        elif period == 'day':\n",
        "            # s_day is daily mean with NaNs for low coverage\n",
        "            exceeded = s_day > limit\n",
        "            counts = exceeded.groupby(exceeded.index.year).sum().astype(int)\n",
        "            for yr, cnt in counts.items():\n",
        "                results_summary.append({\n",
        "                    'pollutant': pollutant,\n",
        "                    'legal_target': legal_target,\n",
        "                    'period_type': 'day',\n",
        "                    'period_label': str(yr),\n",
        "                    'limit': limit,\n",
        "                    'exceedances': int(cnt),\n",
        "                    'allowed_exceedances_per_year': max_exc\n",
        "                })\n",
        "            # detailed events: each day (yyyy-mm-dd)\n",
        "            ev = s_day[exceeded].dropna()\n",
        "            for ts, val in ev.items():\n",
        "                events_rows.append({\n",
        "                    'pollutant': pollutant,\n",
        "                    'period_type': 'day',\n",
        "                    'period_stamp': ts.strftime(\"%Y-%m-%d\"),\n",
        "                    'value': float(val),\n",
        "                    'limit': limit,\n",
        "                    'excess_amount': float(val - limit)\n",
        "                })\n",
        "\n",
        "        elif period in ('8h_daily_max','8h_max_daily'):\n",
        "            # For O3 and CO 8h rules: compute 8h running means (s_8h)\n",
        "            # For daily classification we want the *daily maximum* of the 8h running means.\n",
        "            # For each day, take the maximum of s_8h values that end on that day (i.e. timestamps within that day)\n",
        "            s8 = s_8h.copy()\n",
        "            # assign each s8 timestamp to the day on which the 8h window ends\n",
        "            s8_daily_max = s8.resample('1D').max()   # since s8 index hours, resample day -> default label is day's midnight\n",
        "            exceeded = s8_daily_max > limit\n",
        "            counts = exceeded.groupby(exceeded.index.year).sum().astype(int)\n",
        "            for yr, cnt in counts.items():\n",
        "                results_summary.append({\n",
        "                    'pollutant': pollutant,\n",
        "                    'legal_target': legal_target,\n",
        "                    'period_type': '8h_daily_max',\n",
        "                    'period_label': str(yr),\n",
        "                    'limit': limit,\n",
        "                    'exceedances': int(cnt),\n",
        "                    'allowed_exceedances_per_year': max_exc,\n",
        "                    'three_year_rule': bool(three_year_rule)\n",
        "                })\n",
        "            # detailed events: each day where daily max 8h > limit\n",
        "            ev = s8_daily_max[exceeded].dropna()\n",
        "            for ts, val in ev.items():\n",
        "                # ts is day's midnight; we output yyyy-mm-dd\n",
        "                events_rows.append({\n",
        "                    'pollutant': pollutant,\n",
        "                    'period_type': '8h_daily_max',\n",
        "                    'period_stamp': ts.strftime(\"%Y-%m-%d\"),\n",
        "                    'value': float(val),\n",
        "                    'limit': limit,\n",
        "                    'excess_amount': float(val - limit)\n",
        "                })\n",
        "\n",
        "        elif period == 'year':\n",
        "            # annual mean (calendar year). For annual means we require data coverage:\n",
        "            # compute annual mean of the 1-hour/8h/24h as appropriate: easiest is to use hourly series annual mean\n",
        "            # but require at least 85% coverage in year ideally — we'll implement a simpler threshold: >0.7 * hours_in_year present\n",
        "            yr_groups = s_hour.groupby(s_hour.index.year)\n",
        "            for yr, group in yr_groups:\n",
        "                hours_present = group.count()\n",
        "                hours_in_year = 8760 + (1 if (datetime(yr,1,1).year%4==0 and (yr%100!=0 or yr%400==0)) else 0)\n",
        "                # Use fraction presence threshold 0.7 (relaxed); directive requests 85% but that is more involved to compute per pollutant\n",
        "                if hours_present.mean() < 0.7 * hours_in_year:\n",
        "                    annual_mean = np.nan\n",
        "                else:\n",
        "                    annual_mean = group.mean()\n",
        "                    # group.mean() returns a Series if multiple pollutants; for single pollutant series it's a scalar\n",
        "                    if isinstance(annual_mean, pd.Series):\n",
        "                        annual_mean = float(annual_mean.loc[pollutant])\n",
        "                    else:\n",
        "                        annual_mean = float(annual_mean)\n",
        "                exceeded_flag = False\n",
        "                if pd.notna(annual_mean) and annual_mean > limit:\n",
        "                    exceeded_flag = True\n",
        "                results_summary.append({\n",
        "                    'pollutant': pollutant,\n",
        "                    'legal_target': legal_target,\n",
        "                    'period_type': 'year',\n",
        "                    'period_label': str(yr),\n",
        "                    'limit': limit,\n",
        "                    'exceedances': int(bool(exceeded_flag)),   # 1 if annual mean > limit else 0\n",
        "                    'allowed_exceedances_per_year': max_exc\n",
        "                })\n",
        "                # detailed event if exceeded\n",
        "                if exceeded_flag:\n",
        "                    events_rows.append({\n",
        "                        'pollutant': pollutant,\n",
        "                        'period_type': 'year',\n",
        "                        'period_stamp': str(yr),\n",
        "                        'value': float(annual_mean),\n",
        "                        'limit': limit,\n",
        "                        'excess_amount': float(annual_mean - limit)\n",
        "                    })\n",
        "        else:\n",
        "            # unknown period - skip\n",
        "            print(f\"Skipping unknown period type '{period}' for pollutant {pollutant}\")\n",
        "\n",
        "    # Additional specialised rule: 3-year averages for O3 days and PM2.5 AEI\n",
        "    # For O3: if the 8h_daily_max entry had three_year_rule True, compute 3-year running average of annual 'days > 8h limit' counts\n",
        "    for ent in limits_for_pollutant:\n",
        "        if ent.get('three_year_rule', False):\n",
        "            # compute yearly counts of daily exceedance days (we already collected in results_summary with period_type '8h_daily_max')\n",
        "            # Let's get a simple series of counts by year\n",
        "            # Recompute to ensure correctness:\n",
        "            limit = ent['limit']\n",
        "            s8 = s_8h.copy()\n",
        "            s8_daily_max = s8.resample('1D').max()\n",
        "            exceeded_daily = (s8_daily_max > limit).astype(int).resample('1Y').sum()\n",
        "            # make years aligned as int year\n",
        "            exceeded_by_year = {ts.year: int(v) for ts, v in exceeded_daily.items()}\n",
        "            years_sorted = sorted(exceeded_by_year.keys())\n",
        "            # compute 3-year running average (centered on last year of window): average over year y-2,y-1,y\n",
        "            for i in range(len(years_sorted)):\n",
        "                if i < 2:\n",
        "                    continue  # need 3 years\n",
        "                ywindow = years_sorted[i-2:i+1]\n",
        "                avg_val = int(round(np.mean([exceeded_by_year[y] for y in ywindow]), 3) if ywindow else 0)\n",
        "                results_summary.append({\n",
        "                    'pollutant': pollutant,\n",
        "                    'legal_target': legal_target,\n",
        "                    'period_type': '3year_average_of_daily_8h_exceedance_days',\n",
        "                    'period_label': f\"{ywindow[0]}-{ywindow[-1]}\",\n",
        "                    'limit': limit,\n",
        "                    'exceedances': avg_val,\n",
        "                    'allowed_exceedances_per_year': ent.get('max_exceedances_per_year')\n",
        "                })\n",
        "\n",
        "    # Special for PM2.5: average exposure indicator (AEI) is a 3-year running annual mean of PM2.5 (simplified per-station AEI)\n",
        "    if pollutant == 'PM2.5':\n",
        "        # compute annual means (using s_hour)\n",
        "        ann = s_hour.resample('1Y').mean()\n",
        "        ann_by_year = {ts.year: float(v) for ts, v in ann.items() if pd.notna(v)}\n",
        "        years_sorted = sorted(ann_by_year.keys())\n",
        "        for i in range(len(years_sorted)):\n",
        "            if i < 2:\n",
        "                continue\n",
        "            ywindow = years_sorted[i-2:i+1]\n",
        "            avg_val = np.mean([ann_by_year[y] for y in ywindow])\n",
        "            results_summary.append({\n",
        "                'pollutant': pollutant,\n",
        "                'legal_target': legal_target,\n",
        "                'period_type': 'PM2.5_AEI_3yr',\n",
        "                'period_label': f\"{ywindow[0]}-{ywindow[-1]}\",\n",
        "                'limit': next((e['limit'] for e in limits_for_pollutant if e['period']=='year'), None),\n",
        "                'exceedances': float(avg_val),\n",
        "                'allowed_exceedances_per_year': None\n",
        "            })\n",
        "\n",
        "# ---------- Build output DataFrames ----------\n",
        "df_summary = pd.DataFrame(results_summary)\n",
        "if df_summary.empty:\n",
        "    print(\"No summary results were produced (no pollutant limits matched). Exiting.\")\n",
        "else:\n",
        "    # Pivot/organize summary for readability: keep as flat table with columns:\n",
        "    # pollutant, legal_target, period_type, period_label, limit, exceedances, allowed_exceedances_per_year\n",
        "    df_summary = df_summary[['pollutant','legal_target','period_type','period_label','limit','exceedances','allowed_exceedances_per_year']]\n",
        "    df_summary = df_summary.sort_values(['pollutant','period_type','period_label']).reset_index(drop=True)\n",
        "\n",
        "df_events = pd.DataFrame(events_rows)\n",
        "if not df_events.empty:\n",
        "    df_events = df_events[['pollutant','period_type','period_stamp','value','limit','excess_amount']]\n",
        "    df_events = df_events.sort_values(['pollutant','period_type','period_stamp']).reset_index(drop=True)\n",
        "\n",
        "# ---------- Save CSVs and zip ----------\n",
        "out_summary = \"summary_exceedances.csv\"\n",
        "out_events = \"detailed_exceedance_events.csv\"\n",
        "zip_name = \"eu_exceedance_results.zip\"\n",
        "\n",
        "df_summary.to_csv(out_summary, index=False)\n",
        "df_events.to_csv(out_events, index=False)\n",
        "\n",
        "# Create zip\n",
        "with zipfile.ZipFile(zip_name, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "    zf.write(out_summary)\n",
        "    zf.write(out_events)\n",
        "\n",
        "print(f\"\\nCreated files: {out_summary}, {out_events}, zipped into {zip_name}.\")\n",
        "print(\"First rows of summary:\")\n",
        "print(df_summary.head(20).to_string(index=False))\n",
        "\n",
        "# Trigger download in Colab if available\n",
        "if _in_colab:\n",
        "    print(\"\\nStarting download of the zip file...\")\n",
        "    files.download(zip_name)\n",
        "else:\n",
        "    print(f\"You are not in Colab. The files are saved in the working directory: {os.getcwd()}\")\n",
        "\n",
        "# ---- End cell code ----"
      ]
    }
  ]
}